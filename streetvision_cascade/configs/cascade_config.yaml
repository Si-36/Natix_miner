# StreetVision 4-Stage Cascade Configuration
# Per REALISTIC_DEPLOYMENT_PLAN.md - December 20, 2025
# Target: Subnet 72 (NATIX StreetVision) - Top 15 ranking

# =============================================================================
# STAGE 1: DINOv3-Large Binary Classifier
# =============================================================================
stage1:
  model:
    # NOTE: DINOv3 repos on HF are gated ("manual" acceptance). You must
    # accept the model license on the HF model page before downloads work.
    # DINOv3-ViT-H/16+ variant (3.4GB, best for 24GB GPU performance)
    name: "facebook/dinov3-vith16plus-pretrain-lvd1689m"
    type: "vision_transformer"
    # Hidden size is auto-detected at runtime from a dummy forward pass to
    # avoid breaking on different DINOv3/DINOv2 variants.
    hidden_size: null
    
  # Training Configuration (Frozen Backbone)
  training:
    freeze_backbone: true  # Freeze 1.3B params
    trainable_params: 300000  # Only MLP head (~300K params)
    epochs: 10
    learning_rate: 1e-4
    batch_size: 32
    
  # Classifier Head
  classifier:
    hidden_dims: [768]
    dropout: 0.3
    num_classes: 2  # roadwork vs no-roadwork
    
  # Exit Thresholds (60% exit rate target)
  thresholds:
    positive_exit: 0.88  # p(roadwork) >= 0.88 → EXIT_POSITIVE
    negative_exit: 0.12  # p(roadwork) <= 0.12 → EXIT_NEGATIVE (equiv. p(no-roadwork) >= 0.88)
    
  # Quantization
  quantization:
    method: "tensorrt_fp16"
    original_size_gb: 6.0
    quantized_size_gb: 3.0
    
  # Performance Targets
  targets:
    latency_ms: 25
    accuracy: 0.992  # 99.2% on high-confidence exits
    exit_rate: 0.60  # 60% of queries exit here

# =============================================================================
# STAGE 2: RF-DETR + YOLOv12 Detection Ensemble
# =============================================================================
stage2:
  models:
    rf_detr:
      name: "microsoft/RT-DETR-l"  # RF-DETR-Medium
      type: "object_detection"
      detection_threshold: 0.4
      quantization:
        method: "tensorrt_fp16"
        original_size_gb: 3.8
        quantized_size_gb: 1.9
        
    yolov12:
      name: "yolov12x.pt"
      type: "object_detection"  
      detection_threshold: 0.4
      quantization:
        method: "tensorrt_fp16"
        original_size_gb: 6.2
        quantized_size_gb: 3.1
        
  # Detection Classes for Roadwork
  target_classes:
    - "construction"
    - "cone"
    - "traffic_cone"
    - "barrier"
    - "construction_sign"
    - "excavator"
    - "worker"
    
  # Agreement Logic
  agreement:
    both_zero: "EXIT_NEGATIVE"  # Both detect 0 objects → no roadwork
    both_high: 3  # Both detect >= 3 objects → EXIT_POSITIVE
    major_disagreement: 2  # |rf_count - yolo_count| > 2 → continue
    
  # Performance Targets  
  targets:
    latency_ms: 50  # Parallel execution
    accuracy: 0.97
    exit_rate: 0.25  # 25% of remaining queries

# =============================================================================
# STAGE 3: GLM-4.6V-Flash + Molmo-2 VLM Reasoning
# =============================================================================
stage3:
  models:
    glm_image:
      name: "zai-org/GLM-4.6V-Flash"  # Hub repo id (plan name: GLM-4.6V-Flash-9B)
      type: "vision_language_model"
      quantization:
        method: "autoawq_4bit"
        original_size_gb: 9.0
        quantized_size_gb: 2.3
        
    molmo_video:
      name: "allenai/Molmo2-8B"  # Hub repo id (plan name: Molmo-2-8B)
      type: "vision_language_model"
      max_frames: 8
      quantization:
        method: "autoawq_4bit"
        original_size_gb: 4.5
        quantized_size_gb: 1.2
        
  # Routing Logic
  routing:
    image_queries: "glm_image"
    video_queries: "molmo_video"
    
  # Prompts
  prompts:
    image: |
      Is there roadwork construction visible in this image? 
      Consider: orange cones, barriers, construction workers, equipment.
      Answer yes or no.
      
    video: |
      Is there active roadwork or construction in this video clip?
      Answer yes or no and explain why.
      
  # Exit Thresholds
  thresholds:
    confidence_exit: 0.75  # VLM confidence > 0.75 → exit
    
  # Performance Targets
  targets:
    latency_ms: 200
    accuracy: 0.95
    exit_rate: 0.10

# =============================================================================
# STAGE 4: Florence-2-Large OCR Fallback
# =============================================================================
stage4:
  model:
    name: "microsoft/Florence-2-large"
    type: "vision_language_model"
    task: "<OCR>"
    
  # OCR Keywords for Roadwork
  keywords:
    - "road work"
    - "construction"
    - "lane closed"
    - "detour"
    - "caution"
    - "workers ahead"
    - "slow"
    - "men working"
    
  # Exit Logic
  thresholds:
    multiple_keywords: 2  # >= 2 keywords → 0.85 confidence
    single_keyword: 1  # 1 keyword → 0.70 confidence
    no_keywords: 0  # 0 keywords → 0.60 confidence (default negative)
    
  # No quantization needed (small model)
  quantization:
    method: "none"
    size_gb: 1.5
    
  # Performance Targets
  targets:
    latency_ms: 100
    accuracy: 0.88
    exit_rate: 0.05

# =============================================================================
# OVERALL CASCADE CONFIGURATION
# =============================================================================
cascade:
  # Input Preprocessing (Validator-aligned)
  preprocessing:
    image_size: [224, 224]
    normalization:
      mean: [0.485, 0.456, 0.406]  # ImageNet
      std: [0.229, 0.224, 0.225]
    format: "RGB"
    
  # Augmentations (Training)
  augmentations:
    horizontal_flip: true
    rotation_degrees: 15
    color_jitter:
      brightness: 0.2
      contrast: 0.2
      saturation: 0.2
      
  # VRAM Budget (24GB GPU - RTX 3090/4090)
  vram:
    stage1_dinov3: 3.0
    stage2_rfdetr: 1.9
    stage2_yolo: 3.1
    stage3_glm: 2.3
    stage3_molmo: 1.2
    stage4_florence: 1.5
    total_max: 21.0
    buffer: 3.0
    
  # Latency Budget
  latency:
    weighted_average_target_ms: 60
    validator_timeout_ms: 300
    
# =============================================================================
# ACTIVE LEARNING CONFIGURATION
# =============================================================================
active_learning:
  # FiftyOne Hard-Case Mining
  fiftyone:
    version: "1.5.2"
    hardness_threshold: 0.7
    daily_hard_cases: 200
    
  # SAM 3 Annotation (Month 3+)
  sam3:
    enabled: false  # Enable when annotation is bottleneck
    concepts:
      - "traffic cone"
      - "construction barrier"
      - "roadwork sign"
      - "construction worker with vest"
      - "excavator"
      
  # SDXL Synthetic Data (FREE)
  sdxl:
    model: "stabilityai/stable-diffusion-xl-base-1.0"
    daily_generation: 150
    inference_steps: 30
    
# =============================================================================
# SELF-LEARNING TIERS
# =============================================================================
self_learning:
  # Month 1-2: Supervised + Simple RLVR
  tier1_rlvr:
    enabled: true
    start_month: 1
    reward_accepted: 1.0
    reward_rejected: -1.0
    
  # Month 3-6: SRT (Self-Rewarding Training)
  tier2_srt:
    enabled: false
    start_month: 3
    self_reward_weight: 0.3
    
  # Month 7+: M-GRPO (Stable Self-Learning)
  tier3_mgrpo:
    enabled: false
    start_month: 7
    teacher_momentum: 0.999
    entropy_threshold: 0.3
    group_size: 256

# =============================================================================
# MONITORING & ALERTS
# =============================================================================
monitoring:
  prometheus:
    scrape_interval_s: 15
    retention_days: 30
    
  metrics:
    - "gpu_vram_usage"
    - "latency_p50_ms"
    - "latency_p95_ms"
    - "latency_p99_ms"
    - "cascade_stage_accuracy"
    - "cache_hit_rate"
    - "query_throughput_qps"
    
  alerts:
    gpu_down_minutes: 5
    high_latency_p99_ms: 50
    low_cache_hit_rate: 0.05
    rank_drop_threshold: 30
    model_age_warning_days: 75
    model_age_critical_days: 85

# =============================================================================
# 90-DAY RETRAIN SCHEDULE (CRITICAL!)
# =============================================================================
retrain:
  mandatory_interval_days: 90
  warning_days: [75, 80, 85]
  blue_green_deployment: true
  shadow_traffic_percent: 10
  rollback_accuracy_drop: 0.01  # 1% drop → rollback

