# ULTIMATE COMPLETE 210-TODO IMPLEMENTATION PLAN
## Production-Grade Multi-View DINOv3 Classifier with COMPLETE Infrastructure
## Dec 28, 2025 - ZERO MISSING FEATURES

**Status**: Complete production infrastructure from day 1
**Target**: 90%+ accuracy, ECE <0.05, 6Ã— faster inference, full MLOps
**Total Time**: ~172 hours (~21 days / 3 weeks)
**Philosophy**: Build complete infrastructure NOW, reuse for ALL stages later

---

## EXECUTIVE SUMMARY

**WHY START WITH COMPLETE INFRASTRUCTURE:**
- Build it ONCE, use it for Stages 1, 2, 3, YOLO, FiftyOne, etc.
- Prevents technical debt
- Production-ready from day 1
- Easy to add new models/features later

**WHAT WE'RE BUILDING:**

### Core Model Features
- âœ… Multi-view inference (1 global + 3Ã—3 tiles, batched forward pass)
- âœ… ExPLoRA (+8.2% - BIGGEST gain)
- âœ… DoRAN + Flash Attention 3 (+3%, 2Ã— faster)
- âœ… Safe hyperparameters (dropout 0.3, WD 0.01, LS 0.1)

### Advanced Training
- âœ… 6 optimizers (AdamW, SAM2, Sophia, Muon, AdEMAMix, Schedule-Free)
- âœ… 7 loss functions (CE, Focal, LCRON, Gatekeeper, SupCon, KoLeo)
- âœ… Curriculum learning, MixUp, CutMix, AutoAugment
- âœ… FSDP2 multi-GPU training

### Complete Calibration & Metrics
- âœ… 7 calibration methods (Temperature, Beta, Dirichlet, Platt, Isotonic, Ensemble, SCRC)
- âœ… Conformal prediction (APS, RAPS, CRCP)
- âœ… All metrics (AUROC, AUPRC, ECE, AUGRC, bootstrap CI)
- âœ… Slice-based evaluation (day/night/weather)
- âœ… Drift detection (PSI, KS test, MMD)

### Production Infrastructure
- âœ… DAG pipeline (artifact registry, split contracts, zero leakage)
- âœ… MLOps (DVC, experiment tracking, monitoring)
- âœ… Deployment (ONNX, TensorRT, Docker, K8s, Triton)
- âœ… Monitoring (Prometheus, Grafana, alerts)
- âœ… Testing (unit tests, integration tests, CI/CD)
- âœ… Complete documentation

### Data Infrastructure
- âœ… Multi-dataset fusion (NATIX + Mapillary)
- âœ… Hard negative mining
- âœ… Domain adaptation (DANN)
- âœ… Active learning, pseudo-labeling

**EXPECTED RESULTS:**
- Accuracy: 69% â†’ 90% (+21 points)
- Speed: 6Ã— faster inference (TensorRT + batched multi-view)
- Cost: 10Ã— cheaper training ($120 â†’ $12 with ExPLoRA)
- Calibration: ECE 0.29 â†’ 0.05 (-83% error)
- Production-ready: Full MLOps, monitoring, deployment

---

## COMPLETE FOLDER STRUCTURE

```
stage1_ultimate/
â”œâ”€â”€ configs/                    # Hydra configs
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â”œâ”€â”€ dinov2_multiview.yaml
â”‚   â”‚   â”œâ”€â”€ explora.yaml
â”‚   â”‚   â”œâ”€â”€ doran.yaml
â”‚   â”‚   â””â”€â”€ flash_attention.yaml
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â”œâ”€â”€ baseline.yaml
â”‚   â”‚   â”œâ”€â”€ optimizer_ablation.yaml      # SAM2, Sophia, Muon, etc.
â”‚   â”‚   â”œâ”€â”€ loss_ablation.yaml           # Focal, LCRON, SupCon, etc.
â”‚   â”‚   â””â”€â”€ curriculum.yaml
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ natix.yaml
â”‚   â”‚   â”œâ”€â”€ mapillary.yaml
â”‚   â”‚   â”œâ”€â”€ fusion.yaml
â”‚   â”‚   â””â”€â”€ hard_negative.yaml
â”‚   â”œâ”€â”€ calibration/
â”‚   â”‚   â”œâ”€â”€ temperature.yaml
â”‚   â”‚   â”œâ”€â”€ dirichlet.yaml
â”‚   â”‚   â”œâ”€â”€ scrc.yaml
â”‚   â”‚   â””â”€â”€ conformal.yaml
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”‚   â”œâ”€â”€ metrics.yaml
â”‚   â”‚   â”œâ”€â”€ slicing.yaml
â”‚   â”‚   â””â”€â”€ bootstrap.yaml
â”‚   â”œâ”€â”€ deployment/
â”‚   â”‚   â”œâ”€â”€ onnx.yaml
â”‚   â”‚   â”œâ”€â”€ tensorrt.yaml
â”‚   â”‚   â””â”€â”€ triton.yaml
â”‚   â””â”€â”€ config.yaml                     # Main config
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ contracts/              # Leakage prevention (CRITICAL)
â”‚   â”‚   â”œâ”€â”€ artifact_schema.py  # â­ Single source of truth for paths
â”‚   â”‚   â”œâ”€â”€ split_contracts.py  # â­ Split usage rules (enforced as code)
â”‚   â”‚   â””â”€â”€ validators.py       # â­ Fail-fast checking
â”‚   â”‚
â”‚   â”œâ”€â”€ pipeline/               # DAG orchestrator
â”‚   â”‚   â”œâ”€â”€ phase_spec.py       # Phase contracts
â”‚   â”‚   â””â”€â”€ dag_engine.py       # â­ Dependency resolution
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                 # All model components
â”‚   â”‚   â”œâ”€â”€ module.py           # â­ LightningModule (main)
â”‚   â”‚   â”œâ”€â”€ multi_view.py       # â­ Multi-view inference (1+9 crops)
â”‚   â”‚   â”œâ”€â”€ explora.py          # â­ ExPLoRA (+8.2%)
â”‚   â”‚   â”œâ”€â”€ doran.py            # DoRAN (+1-3%)
â”‚   â”‚   â”œâ”€â”€ flash_attention.py  # Flash Attention 3 (1.5-2Ã— speed)
â”‚   â”‚   â”œâ”€â”€ backbone.py         # DINOv3 wrapper
â”‚   â”‚   â”œâ”€â”€ head.py             # Classification head
â”‚   â”‚   â”œâ”€â”€ domain_adaptation.py # DANN discriminator
â”‚   â”‚   â””â”€â”€ uncertainty.py      # 7D uncertainty features + failure gate
â”‚   â”‚
â”‚   â”œâ”€â”€ data/                   # Data loading
â”‚   â”‚   â”œâ”€â”€ datamodule.py       # â­ LightningDataModule
â”‚   â”‚   â”œâ”€â”€ datasets.py         # NATIX, Mapillary
â”‚   â”‚   â”œâ”€â”€ mapillary.py        # Mapillary Vistas dataset
â”‚   â”‚   â”œâ”€â”€ balanced_dataset.py # Multi-dataset balancing
â”‚   â”‚   â”œâ”€â”€ splits.py           # 4-way split generation
â”‚   â”‚   â”œâ”€â”€ transforms.py       # Augmentation (MixUp, CutMix, AutoAugment)
â”‚   â”‚   â””â”€â”€ hard_negative.py    # Hard negative mining
â”‚   â”‚
â”‚   â”œâ”€â”€ training/               # Training logic
â”‚   â”‚   â”œâ”€â”€ ema.py              # EMA implementation
â”‚   â”‚   â”œâ”€â”€ explora_pretrain.py # ExPLoRA pretraining
â”‚   â”‚   â”œâ”€â”€ curriculum.py       # Curriculum learning
â”‚   â”‚   â””â”€â”€ fsdp.py             # FSDP2 multi-GPU
â”‚   â”‚
â”‚   â”œâ”€â”€ optimizers/             # Advanced optimizers
â”‚   â”‚   â”œâ”€â”€ sam2.py             # SAM2 (+1.5%)
â”‚   â”‚   â”œâ”€â”€ sophia.py           # Sophia (2Ã— faster training)
â”‚   â”‚   â”œâ”€â”€ muon.py             # Muon (higher LR)
â”‚   â”‚   â”œâ”€â”€ ademamix.py         # AdEMAMix (third momentum)
â”‚   â”‚   â””â”€â”€ schedule_free.py    # Schedule-Free (no LR scheduler)
â”‚   â”‚
â”‚   â”œâ”€â”€ losses/                 # Advanced loss functions
â”‚   â”‚   â”œâ”€â”€ focal.py            # Focal Loss (class imbalance)
â”‚   â”‚   â”œâ”€â”€ lcron.py            # LCRON (cascade ranking)
â”‚   â”‚   â”œâ”€â”€ gatekeeper.py       # Gatekeeper (deferral)
â”‚   â”‚   â”œâ”€â”€ supcon.py           # SupCon (supervised contrastive)
â”‚   â”‚   â””â”€â”€ koleo.py            # KoLeo (feature collapse prevention)
â”‚   â”‚
â”‚   â”œâ”€â”€ metrics/                # Evaluation
â”‚   â”‚   â”œâ”€â”€ calibration.py      # ECE, MCE, ACE, Brier, NLL
â”‚   â”‚   â”œâ”€â”€ selective.py        # AUGRC, risk-coverage curves
â”‚   â”‚   â”œâ”€â”€ bootstrap.py        # Bootstrap CI (95% confidence intervals)
â”‚   â”‚   â”œâ”€â”€ classification.py   # AUROC, AUPRC, F1
â”‚   â”‚   â”œâ”€â”€ slicing.py          # Slice-based evaluation
â”‚   â”‚   â”œâ”€â”€ cascade.py          # Cascade metrics
â”‚   â”‚   â””â”€â”€ fairness.py         # Fairness metrics
â”‚   â”‚
â”‚   â”œâ”€â”€ calibration/            # Post-hoc calibration
â”‚   â”‚   â”œâ”€â”€ temperature.py      # Temperature scaling
â”‚   â”‚   â”œâ”€â”€ beta.py             # Beta calibration
â”‚   â”‚   â”œâ”€â”€ dirichlet.py        # Dirichlet calibration
â”‚   â”‚   â”œâ”€â”€ platt.py            # Platt scaling
â”‚   â”‚   â”œâ”€â”€ isotonic.py         # Isotonic regression
â”‚   â”‚   â”œâ”€â”€ ensemble.py         # Ensemble temperature
â”‚   â”‚   â”œâ”€â”€ scrc.py             # Split Conformal Risk Control
â”‚   â”‚   â””â”€â”€ conformal.py        # APS, RAPS, CRCP
â”‚   â”‚
â”‚   â”œâ”€â”€ monitoring/             # Drift detection & monitoring
â”‚   â”‚   â”œâ”€â”€ drift.py            # PSI, KS test, MMD
â”‚   â”‚   â”œâ”€â”€ prometheus.py       # Prometheus exporter
â”‚   â”‚   â””â”€â”€ alerts.py           # Alert system
â”‚   â”‚
â”‚   â”œâ”€â”€ deployment/             # Deployment infrastructure
â”‚   â”‚   â”œâ”€â”€ onnx_export.py      # ONNX export
â”‚   â”‚   â”œâ”€â”€ tensorrt.py         # TensorRT optimization (3-5Ã— speedup)
â”‚   â”‚   â”œâ”€â”€ triton.py           # Triton Inference Server
â”‚   â”‚   â”œâ”€â”€ docker/
â”‚   â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â”‚   â”œâ”€â”€ k8s/
â”‚   â”‚   â”‚   â”œâ”€â”€ deployment.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ service.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ ingress.yaml
â”‚   â”‚   â”‚   â””â”€â”€ hpa.yaml
â”‚   â”‚   â”œâ”€â”€ ab_testing.py       # A/B testing framework
â”‚   â”‚   â””â”€â”€ shadow.py           # Shadow deployment
â”‚   â”‚
â”‚   â”œâ”€â”€ mlops/                  # MLOps infrastructure
â”‚   â”‚   â”œâ”€â”€ dvc_config.py       # DVC setup
â”‚   â”‚   â”œâ”€â”€ experiment_tracker.py # Experiment tracking
â”‚   â”‚   â””â”€â”€ model_registry.py   # Model versioning
â”‚   â”‚
â”‚   â”œâ”€â”€ evaluation/             # Evaluation reports
â”‚   â”‚   â”œâ”€â”€ reliability.py      # Reliability diagrams
â”‚   â”‚   â”œâ”€â”€ calibration_summary.py # Calibration comparison
â”‚   â”‚   â”œâ”€â”€ summary_report.py   # Model comparison
â”‚   â”‚   â””â”€â”€ cross_dataset.py    # Cross-dataset validation
â”‚   â”‚
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ logging.py
â”‚       â””â”€â”€ visualization.py
â”‚
â”œâ”€â”€ scripts/                    # CLI entry points
â”‚   â”œâ”€â”€ 10_train_baseline.py
â”‚   â”œâ”€â”€ 15_train_explora.py
â”‚   â”œâ”€â”€ 20_calibrate.py
â”‚   â”œâ”€â”€ 30_evaluate.py
â”‚   â”œâ”€â”€ 40_export.py
â”‚   â””â”€â”€ train_cli.py            # Main CLI (DAG engine)
â”‚
â”œâ”€â”€ tests/                      # Testing infrastructure
â”‚   â”œâ”€â”€ unit/
â”‚   â”‚   â”œâ”€â”€ test_multi_view.py
â”‚   â”‚   â”œâ”€â”€ test_calibration.py
â”‚   â”‚   â””â”€â”€ test_metrics.py
â”‚   â”œâ”€â”€ integration/
â”‚   â”‚   â”œâ”€â”€ test_dag_pipeline.py
â”‚   â”‚   â”œâ”€â”€ test_training.py
â”‚   â”‚   â””â”€â”€ test_deployment.py
â”‚   â””â”€â”€ conftest.py
â”‚
â”œâ”€â”€ docs/                       # Documentation
â”‚   â”œâ”€â”€ ARCHITECTURE.md
â”‚   â”œâ”€â”€ API_REFERENCE.md
â”‚   â”œâ”€â”€ DEPLOYMENT_GUIDE.md
â”‚   â””â”€â”€ CONTRIBUTING.md
â”‚
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ ci.yml              # CI/CD pipeline
â”‚       â””â”€â”€ deploy.yml
â”‚
â”œâ”€â”€ deployment/
â”‚   â”œâ”€â”€ monitoring/
â”‚   â”‚   â””â”€â”€ grafana/
â”‚   â”‚       â””â”€â”€ dashboards/
â”‚   â””â”€â”€ docker-compose.yml
â”‚
â”œâ”€â”€ train.py                    # Main entry point
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ .dvcignore
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## IMPLEMENTATION TIMELINE (21 Days / 172 Hours)

### Week 1: Core Infrastructure (Days 1-7, 56h)

**Tier 0: DAG Pipeline Architecture (Days 1-2, 14h) - TODOs 121-140**
- âœ… Artifact registry (single source of truth for paths)
- âœ… Split contracts (zero data leakage, enforced as code)
- âœ… Validators (fail-fast artifact checking)
- âœ… Phase specifications (DAG nodes with contracts)
- âœ… DAG engine (automatic dependency resolution)
- âœ… Clean CLI entry point
- âœ… Hydra configuration structure
- âœ… Integration tests

**Foundation (Days 3-4, 12h) - TODOs 1-20**
- âœ… File cleanup (remove duplicates)
- âœ… Fix trainer call signatures
- âœ… Implement SCRC stub methods
- âœ… Multi-view generator (1 global + 9 tiles, 15% overlap)
- âœ… Top-K mean aggregator (K=2 or 3)
- âœ… Attention aggregator

**Core Model (Days 5-7, 30h) - TODOs 141-160 (SOTA Features)**
- âœ… ExPLoRA implementation (+8.2% - BIGGEST gain)
- âœ… DoRAN head (+1-3% over LoRA)
- âœ… Flash Attention 3 (1.5-2Ã— faster)
- âœ… Lightning Module + DataModule
- âœ… EMA implementation
- âœ… 7D uncertainty features
- âœ… Failure gate predictor (AUROC 0.85)

---

### Week 2: Training & Calibration (Days 8-14, 68h)

**Advanced Training (Days 8-9, 16h) - TODOs 31-50**
- âœ… 6 optimizer implementations (SAM2, Sophia, Muon, AdEMAMix, Schedule-Free, AdamW)
- âœ… 7 loss function implementations (CE, Focal, LCRON, Gatekeeper, SupCon, KoLeo)
- âœ… Curriculum learning
- âœ… MixUp, CutMix, AutoAugment
- âœ… FSDP2 multi-GPU training

**Complete Calibration (Days 10-11, 24h) - TODOs 161-180**
- âœ… Temperature scaling (LBFGS optimization, -50% ECE)
- âœ… Beta calibration (MLE fitting, -65% ECE)
- âœ… Class-wise temperature (-60% ECE)
- âœ… Platt scaling (SGD optimization, -50% ECE)
- âœ… Isotonic regression (-55% ECE)
- âœ… Ensemble temperature (-70% ECE)
- âœ… Dirichlet calibration (-60% ECE)
- âœ… Calibration by slice
- âœ… Reliability diagram generator
- âœ… Calibration summary report

**Complete Evaluation (Days 12-13, 14h) - TODOs 51-70 + 171-180**
- âœ… AUROC/AUPRC computation
- âœ… Precision/Recall/F1
- âœ… ECE/MCE/SCE computation
- âœ… Brier score, NLL
- âœ… Risk-coverage curve (AUGRC)
- âœ… Coverage-at-risk, risk-at-coverage
- âœ… Cascade metrics
- âœ… Fairness metrics
- âœ… Slice-based evaluation (day/night/weather)
- âœ… Evaluation summary report

**Drift Detection & Tuning (Day 14, 14h) - TODOs 86-110**
- âœ… Bootstrap confidence intervals (95% CI)
- âœ… PSI (Population Stability Index)
- âœ… KS test (Kolmogorov-Smirnov)
- âœ… MMD (Maximum Mean Discrepancy)
- âœ… Embedding shift detection
- âœ… Hyperparameter sweep grids (LR, batch size, LoRA rank)
- âœ… Bayesian optimization (Optuna/TPE)

---

### Week 3: Production Infrastructure (Days 15-21, 48h)

**Deployment Infrastructure (Days 15-16, 15h) - TODOs 181-195**
- âœ… ONNX export (3.5Ã— speedup)
- âœ… TensorRT optimization (3-5Ã— speedup)
- âœ… Triton Inference Server (production serving)
- âœ… Docker containerization
- âœ… Kubernetes deployment manifests (deployment, service, ingress, HPA)
- âœ… Prometheus metrics exporter
- âœ… Grafana dashboards
- âœ… A/B testing framework
- âœ… Shadow deployment
- âœ… Monitoring & alerting
- âœ… Load testing, model registry, versioning, rollback

**Multi-Dataset Fusion (Days 17-18, 10h) - TODOs 111-120 + 196-210**
- âœ… Mapillary Vistas integration (25K images, 21GB)
- âœ… Dataset balancing (50/50 or 30/70 NATIX/Mapillary)
- âœ… Domain adaptation (DANN discriminator)
- âœ… Hard negative mining (orange objects, construction signs)
- âœ… Cross-dataset validation
- âœ… Pseudo-labeling, active learning
- âœ… Multi-dataset calibration
- âœ… CutMix across datasets
- âœ… Dataset performance analysis

**Testing & Documentation (Days 19-21, 23h)**
- âœ… Unit tests (multi-view, calibration, metrics)
- âœ… Integration tests (DAG pipeline, training, deployment)
- âœ… CI/CD pipeline (.github/workflows/)
- âœ… Architecture documentation
- âœ… API reference
- âœ… Deployment guide
- âœ… End-to-end pipeline test
- âœ… Accuracy verification (88-92%+)
- âœ… Speed benchmarking (>30 FPS)
- âœ… Production readiness checklist
- âœ… Complete documentation review

---

## COMPLETE 210-TODO CHECKLIST

### Tier 0: DAG Pipeline Architecture (14h) - TODOs 121-140 â­â­â­

- [ ] **TODO 121**: Create `contracts/artifact_schema.py` - Artifact Registry (1.5h)
- [ ] **TODO 122**: Create `contracts/split_contracts.py` - Leakage Prevention (1h)
- [ ] **TODO 123**: Create `contracts/validators.py` - Fail-Fast Checking (2h)
- [ ] **TODO 124**: Create `pipeline/phase_spec.py` - DAG Phase Specifications (2.5h)
- [ ] **TODO 125**: Create `pipeline/dag_engine.py` - DAG Pipeline Orchestrator (2h)
- [ ] **TODO 126**: Create `scripts/train_cli.py` - Clean CLI Entry Point (1h)
- [ ] **TODO 127**: Create base config structure with Hydra (1h)
- [ ] **TODO 128**: Create phase-specific configs (1h)
- [ ] **TODO 129**: Update existing code to use ArtifactSchema (1h)
- [ ] **TODO 130**: Add integration test for DAG pipeline (1h)

### Foundation (12h) - TODOs 1-20

- [ ] **TODO 1-5**: Cleanup & Fixes (2h)
  - Delete duplicate files (peft.py, peft_custom.py, calibrate_gate.py)
  - Fix scripts/20_train.py trainer call
  - Implement calibration/scrc.py methods
- [ ] **TODO 6-10**: Multi-View Generator Schema (3h)
- [ ] **TODO 11-15**: Multi-View Aggregation (3h)
- [ ] **TODO 16-20**: Multi-View Integration & Testing (4h)

### Tier 1: SOTA Features (28h) - TODOs 141-160 â­â­â­

- [ ] **TODO 141**: Create `models/explora.py` - ExPLoRA PEFT (2.5h) **+8.2%**
- [ ] **TODO 142**: Create `models/doran_head.py` - DoRAN PEFT (2.5h) **+1-3%**
- [ ] **TODO 143**: Create `models/flash_attn3.py` - Flash Attention 3 (2h) **1.5-2Ã— speed**
- [ ] **TODO 144**: Create `models/multi_view.py` - Multi-View Inference (3h) **+3-5%**
- [ ] **TODO 145**: Create `models/uncertainty.py` - 7D Uncertainty Features (3h)
- [ ] **TODO 146**: Create `models/failure_gate.py` - Failure Predictor (2.5h) **AUROC 0.85**
- [ ] **TODO 147**: Create `losses/lcron.py` - LCRON Loss (2h) **+3.5%**
- [ ] **TODO 148**: Create `losses/gatekeeper.py` - Gatekeeper Loss (1.5h) **+2.3%**
- [ ] **TODO 149**: Hard negative mining (1.5h) **+2%**
- [ ] **TODO 150**: Hierarchical validation (1h)
- [ ] **TODO 151**: torch.compile integration (1h) **1.3-2Ã— speed**
- [ ] **TODO 152**: Mixed precision training (1h) **2Ã— memory**
- [ ] **TODO 153**: Gradient checkpointing (1h) **3Ã— memory**
- [ ] **TODO 154**: FSDP2 multi-GPU (1.5h) **2Ã— memory reduction**
- [ ] **TODO 155**: Curriculum learning (1.5h) **+1-2%**
- [ ] **TODO 156**: Advanced augmentation (MixUp, CutMix, AutoAugment) (1.5h) **+1-2%**
- [ ] **TODO 157**: Hierarchical Stochastic Attention (1h)
- [ ] **TODO 158**: Domain discriminator (DANN) (1.5h) **+1-2%**
- [ ] **TODO 159**: SCRC/CRCP implementation (1.5h)
- [ ] **TODO 160**: Integration testing for SOTA features (1h)

### Advanced Training (16h) - TODOs 31-50

- [ ] **TODO 31-40**: Optimizer Ablation (8h)
  - AdamW baseline
  - SAM2 (+1.5%, 2Ã— slower)
  - Sophia (+1%, 2Ã— FASTER)
  - Schedule-Free (no LR scheduler)
  - AdEMAMix (+0.5%)
  - Muon (+1.5%)
- [ ] **TODO 41-50**: Loss Function Ablation (8h)
  - Cross-entropy baseline
  - Focal Loss (+1% if imbalanced)
  - LCRON (+3.5% cascade recall)
  - Gatekeeper (+2.3% deferral)
  - SupCon (+1.5%)
  - KoLeo (+0.5% stability)
  - Combined losses

### Evaluation (12h) - TODOs 51-70

- [ ] **TODO 51-60**: Evaluation Metrics Schema (6h)
  - AUROC, AUPRC, F1
  - ECE, MCE, SCE, Brier, NLL
  - AUGRC, risk-coverage curves
- [ ] **TODO 61-70**: Slice-Based Evaluation (6h)
  - Day/night/dawn/dusk slices
  - Weather slices (clear/rain/snow/fog)
  - Camera source slices
  - Confidence bin slices

### Calibration (10h) - TODOs 71-85

- [ ] **TODO 71-80**: Calibration Methods (6h)
  - Temperature scaling (-50% ECE)
  - Class-wise temperature (-60% ECE)
  - Platt scaling (-50% ECE)
  - Beta calibration (-65% ECE)
  - Isotonic regression (-55% ECE)
  - Ensemble temperature (-70% ECE)
  - Dirichlet calibration (-60% ECE)
- [ ] **TODO 81-85**: Conformal Prediction (4h)
  - Split conformal
  - SCRC (robust to contamination)
  - CRCP (zero-shot models)
  - APS (adaptive prediction sets)
  - RAPS (regularized APS)

### Tier 2: Calibration & Evaluation Implementation (24h) - TODOs 161-180

- [ ] **TODO 161-170**: Calibration Implementation (10h)
  - Full code for all 7 calibration methods
  - Reliability diagram generator
  - Calibration summary report
- [ ] **TODO 171-180**: Evaluation Implementation (14h)
  - AUROC/AUPRC computation
  - Precision/Recall/F1 computation
  - ECE/MCE/SCE computation
  - Brier score, NLL
  - Risk-coverage curves
  - Cascade metrics
  - Fairness metrics
  - Evaluation summary report

### Bootstrap & Drift (8h) - TODOs 86-95

- [ ] **TODO 86-90**: Bootstrap Confidence Intervals (4h)
  - 1000 bootstrap resamples
  - 95% confidence intervals
  - Statistical significance testing
- [ ] **TODO 91-95**: Drift Detection (4h)
  - PSI (Population Stability Index)
  - KS test (Kolmogorov-Smirnov)
  - MMD (Maximum Mean Discrepancy)
  - Embedding shift detection

### Hyperparameter Tuning (10h) - TODOs 96-110

- [ ] **TODO 96-105**: Hyperparameter Sweep Grids (6h)
  - LR sweep: [1e-5, 5e-5, 1e-4, 5e-4, 1e-3, 5e-3]
  - Weight decay sweep: [0.0, 0.01, 0.05, 0.1, 0.5]
  - Batch size sweep: [8, 16, 32, 64, 128]
  - LoRA rank sweep: [4, 8, 16, 32, 64]
  - Dropout sweep: [0.0, 0.1, 0.2, 0.3, 0.4, 0.5]
- [ ] **TODO 106-110**: Bayesian Optimization (4h)
  - Optuna/TPE sampler
  - Multi-parameter search
  - Objective: val_select/accuracy

### Data Fusion (8h) - TODOs 111-120

- [ ] **TODO 111-120**: Multi-Dataset Fusion Schema (8h)
  - Naive concatenation
  - Balanced sampling (50/50)
  - Weighted loss (inverse frequency)
  - Domain stratified (equal per domain)
  - Hard negative focused (+2.3%)
  - Dataset mixing ratios (30/70 recommended)
  - Class balancing (WeightedRandomSampler)
  - Data quality checks (duplicates, outliers, label consistency)

### Tier 3: Deployment (15h) - TODOs 181-195 â­â­

- [ ] **TODO 181**: ONNX Export (1h) **3.5Ã— speedup**
- [ ] **TODO 182**: TensorRT Optimization (2h) **3-5Ã— speedup**
- [ ] **TODO 183**: Triton Inference Server (2h)
- [ ] **TODO 184**: Docker Containerization (1.5h)
- [ ] **TODO 185**: Kubernetes Deployment Manifests (1.5h)
- [ ] **TODO 186**: Prometheus Metrics Exporter (1.5h)
- [ ] **TODO 187**: Grafana Dashboards (1.5h)
- [ ] **TODO 188**: A/B Testing Framework (2h)
- [ ] **TODO 189**: Shadow Deployment (1.5h)
- [ ] **TODO 190**: Monitoring & Alerting (1h)
- [ ] **TODO 191-195**: Additional Deployment (5h)
  - Load testing (Locust)
  - Model registry (MLflow)
  - Versioning system
  - Rollback mechanism
  - Production checklist

### Tier 4: Multi-Dataset Fusion (10h) - TODOs 196-210

- [ ] **TODO 196**: Mapillary Vistas Integration (2h) **25K images, 21GB**
- [ ] **TODO 197**: Dataset Balancing (50/50 or 30/70) (1.5h) **+2-3%**
- [ ] **TODO 198**: Domain Adaptation (DANN) (2h) **+1-2%**
- [ ] **TODO 199**: Hard Negative Mining from Mapillary (1.5h)
- [ ] **TODO 200**: Cross-dataset Validation (1h)
- [ ] **TODO 201-205**: Additional Fusion Components (5h)
  - Pseudo-labeling unlabeled Mapillary
  - Active learning
  - Multi-dataset calibration
  - CutMix across datasets
  - Dataset performance analysis
- [ ] **TODO 206-210**: Final Validation (5h)
  - End-to-end pipeline test
  - Accuracy verification (88-92%+)
  - Speed benchmarking (>30 FPS)
  - Production readiness checklist
  - Complete documentation review

---

## SUCCESS CRITERIA

**Must achieve ALL of these:**

1. âœ… **Accuracy**: â‰¥88% on validation set (target: 90%)
2. âœ… **Calibration**: ECE â‰¤0.10 (target: 0.05)
3. âœ… **Speed**: â‰¥30 FPS inference on single GPU (â‰¥60 FPS with TensorRT)
4. âœ… **Cost**: Training cost â‰¤$15 (with ExPLoRA)
5. âœ… **Leakage**: Zero data leakage (enforced by split contracts)
6. âœ… **Multi-view**: Batched forward pass working correctly
7. âœ… **Architecture**: Complete DAG pipeline with artifact registry
8. âœ… **Metrics**: All metrics implemented (AUROC, ECE, bootstrap CI, slicing)
9. âœ… **Calibration**: All 7 methods + conformal prediction working
10. âœ… **Deployment**: ONNX, TensorRT, Docker, K8s ready
11. âœ… **Monitoring**: Prometheus, Grafana, alerts working
12. âœ… **Testing**: All unit + integration tests passing
13. âœ… **Documentation**: Complete architecture + API docs
14. âœ… **MLOps**: DVC, experiment tracking, model registry working

---

## NEXT STEPS

**Day 1: Start with Tier 0 (DAG Pipeline Architecture)**

1. âœ… Create `src/contracts/artifact_schema.py`
2. âœ… Create `src/contracts/split_contracts.py`
3. âœ… Create `src/contracts/validators.py`
4. âœ… Create `src/pipeline/phase_spec.py`
5. âœ… Create `src/pipeline/dag_engine.py`
6. âœ… Create `scripts/train_cli.py`
7. âœ… Create Hydra configs
8. âœ… Test DAG pipeline

This gives us ZERO data leakage and solid foundation for everything else!

**Ready to start implementation!** ðŸš€
