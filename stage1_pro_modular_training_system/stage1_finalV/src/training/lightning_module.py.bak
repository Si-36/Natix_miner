"""
ðŸ”¥ **PyTorch Lightning 2.4 Module (2025 Best Practices)**
Complete LightningModule with torch.compile, FSDP2, multiple val loaders
"""

import torch
import torch.nn as nn
from typing import Dict, Optional, Any, List, Tuple
import numpy as np

import lightning as L
from lightning.pytorch.callbacks import ModelCheckpoint
from lightning.pytorch.utilities import rank_zero_debug


class RoadworkLightningModule(L.LightningModule):
    """
    Production-grade Lightning 2.4 module for Stage-1 Pro System
    
    Features (2025 best practices):
    - torch.compile: 30-50% FREE speedup
    - Multiple val loaders: val_select, val_calib, val_test
    - W&B logging
    - Gradient clipping
    - Learning rate monitoring
    """
    
    def __init__(
        self,
        backbone: nn.Module,
        head: nn.Module,
        learning_rate: float = 1e-4,
        weight_decay: float = 0.05,
        num_classes: int = 2,
        compile_model: bool = True,
        label_smoothing: float = 0.0,
        optimizer_name: str = "adamw",
        scheduler_name: str = "cosine",
        warmup_epochs: int = 5,
        scheduler_min_lr: float = 1e-6,
    ):
        super().__init__()
        
        # Save hyperparameters
        self.save_hyperparameters({
            "learning_rate": learning_rate,
            "weight_decay": weight_decay,
            "label_smoothing": label_smoothing,
            "optimizer": optimizer_name,
            "scheduler": scheduler_name,
            "compile_model": compile_model,
        })
        
        # Model components
        self.backbone = backbone
        self.head = head
        
        # Training config
        self.learning_rate = learning_rate
        self.weight_decay = weight_decay
        self.num_classes = num_classes
        self.compile_model = compile_model
        self.label_smoothing = label_smoothing
        self.optimizer_name = optimizer_name
        self.scheduler_name = scheduler_name
        self.warmup_epochs = warmup_epochs
        self.scheduler_min_lr = scheduler_min_lr
        
        # Loss function
        self.criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)
        
        # Metrics
        self.train_accuracy = L.metrics.Accuracy(task="multiclass", num_classes=num_classes)
        self.val_accuracy = L.metrics.Accuracy(task="multiclass", num_classes=num_classes)
        self.val_auroc = L.metrics.AUROC(task="multiclass", num_classes=num_classes)
        
        # Store validation outputs for calibration
        self.val_select_logits = []
        self.val_select_labels = []
        self.val_calib_logits = []
        self.val_calib_labels = []
        self.val_test_logits = []
        self.val_test_labels = []
        
        # Compile flag
        self.is_compiled = False
    
    def configure_optimizers(self):
        """Configure optimizer (2025 best practices)"""
        
        if self.optimizer_name == "adamw":
            optimizer = torch.optim.AdamW(
                self.parameters(),
                lr=self.learning_rate,
                weight_decay=self.weight_decay,
                betas=(0.9, 0.999),
                eps=1e-8,
                amsgrad=False,
                fused=True,  # 2025: Faster implementation
            )
        else:
            optimizer = torch.optim.AdamW(self.parameters(), lr=self.learning_rate)
        
        # Scheduler
        if self.scheduler_name == "cosine":
            scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
                optimizer,
                T_max=self.trainer.max_epochs if hasattr(self.trainer, 'max_epochs') else 50,
                eta_min=self.scheduler_min_lr,
            )
        elif self.scheduler_name == "onecycle":
            scheduler = torch.optim.lr_scheduler.OneCycleLR(
                optimizer,
                max_lr=self.learning_rate,
                total_steps=self.trainer.estimated_stepping_batches if hasattr(self.trainer, 'estimated_stepping_batches') else 10000,
                pct_start=self.warmup_epochs / 50,
            )
        else:
            scheduler = None
        
        return optimizer
    
    def configure_callbacks(self):
        """Configure Lightning callbacks"""
        callbacks = []
        
        # Model checkpointing (monitors ONLY val_select/accuracy - NO LEAKAGE)
        callbacks.append(
            ModelCheckpoint(
                dirpath="outputs/checkpoints",
                filename="best-{epoch:02d}-{val_select/accuracy:.2f}",
                monitor="val_select/accuracy",
                save_top_k=1,
                mode="max",
                save_last=True,
            )
        )
        
        return callbacks
    
    def forward(self, batch):
        """Forward pass"""
        images, labels = batch
        
        # Extract features from backbone
        features = self.backbone.extract_features(images)
        
        # Head forward
        logits = self.head(features)
        
        return logits
    
    def training_step(self, batch, batch_idx):
        """Training step"""
        images, labels = batch
        
        logits = self(images)
        
        # Compute loss
        loss = self.criterion(logits, labels)
        
        # Compute metrics
        preds = torch.argmax(logits, dim=1)
        train_acc = self.train_accuracy(preds, labels)
        
        # Log metrics
        self.log("train/loss", loss, prog_bar=True, on_step=True, sync_dist=True)
        self.log("train/accuracy", train_acc, prog_bar=True, on_step=True, sync_dist=True)
        
        # Learning rate
        opt = self.optimizers()
        lr = opt.param_groups[0]["lr"]
        self.log("train/lr", lr, prog_bar=True, on_step=True, sync_dist=True)
        
        return {"loss": loss}
    
    def validation_step(self, batch, batch_idx, dataloader_idx=0):
        """Validation step for val_select (model selection)"""
        images, labels = batch
        logits = self(images)
        
        # Compute metrics
        preds = torch.argmax(logits, dim=1)
        acc = self.val_accuracy(preds, labels)
        auroc = self.val_auroc(logits, labels)
        
        # Store for calibration
        probs = torch.softmax(logits, dim=1)
        self.val_select_logits.append(probs.detach().cpu())
        self.val_select_labels.append(labels.detach().cpu())
        
        # Log metrics (CRITICAL: tag with val_select to avoid leakage)
        self.log("val_select/loss", self.criterion(logits, labels), prog_bar=False, sync_dist=True)
        self.log("val_select/accuracy", acc, prog_bar=True, sync_dist=True, batch_size=images.size(0))
        self.log("val_select/auroc", auroc, prog_bar=True, sync_dist=True, batch_size=images.size(0))
        
        return {
            "val_select/accuracy": acc,
            "val_select/auroc": auroc,
        }
    
    def validation_step(self, batch, batch_idx, dataloader_idx=1):
        """Validation step for val_calib (policy fitting)"""
        images, labels = batch
        logits = self(images)
        
        # Compute metrics
        preds = torch.argmax(logits, dim=1)
        acc = self.val_accuracy(preds, labels)
        
        # Store for calibration (CRITICAL: save probabilities for temperature scaling)
        probs = torch.softmax(logits, dim=1)
        self.val_calib_logits.append(probs.detach().cpu())
        self.val_calib_labels.append(labels.detach().cpu())
        
        # Log metrics (CRITICAL: tag with val_calib)
        self.log("val_calib/loss", self.criterion(logits, labels), prog_bar=False, sync_dist=True)
        self.log("val_calib/accuracy", acc, prog_bar=False, sync_dist=True, batch_size=images.size(0))
        
        return {
            "val_calib/accuracy": acc,
        }
    
    def validation_step(self, batch, batch_idx, dataloader_idx=2):
        """Validation step for val_test (final evaluation)"""
        images, labels = batch
        logits = self(images)
        
        # Compute metrics
        preds = torch.argmax(logits, dim=1)
        acc = self.val_accuracy(preds, labels)
        auroc = self.val_auroc(logits, labels)
        
        # Store for final evaluation
        probs = torch.softmax(logits, dim=1)
        self.val_test_logits.append(probs.detach().cpu())
        self.val_test_labels.append(labels.detach().cpu())
        
        # Log metrics
        self.log("val_test/loss", self.criterion(logits, labels), prog_bar=False, sync_dist=True)
        self.log("val_test/accuracy", acc, prog_bar=False, sync_dist=True, batch_size=images.size(0))
        self.log("val_test/auroc", auroc, prog_bar=False, sync_dist=True, batch_size=images.size(0))
        
        return {
            "val_test/accuracy": acc,
            "val_test/auroc": auroc,
        }
    
    def on_validation_epoch_end(self):
        """Called at end of validation epoch"""
        # Clear stored data
        self.val_select_logits.clear()
        self.val_select_labels.clear()
        self.val_calib_logits.clear()
        self.val_calib_labels.clear()
        self.val_test_logits.clear()
        self.val_test_labels.clear()
    
    def on_train_start(self):
        """Called at start of training"""
        rank_zero_debug("Starting training...")
        rank_zero_debug(f"Learning rate: {self.learning_rate}")
        rank_zero_debug(f"Weight decay: {self.weight_decay}")
        rank_zero_debug(f"Label smoothing: {self.label_smoothing}")
        
        # Compile model if requested (2025 best practice)
        if self.compile_model and not self.is_compiled:
            rank_zero_debug("Compiling model with torch.compile (30-50% speedup)...")
            self.backbone = torch.compile(self.backbone, mode="max-autotune", fullgraph=False)
            self.head = torch.compile(self.head, mode="max-autotune", fullgraph=False)
            self.is_compiled = True
            rank_zero_debug("Model compiled successfully!")
    
    def on_fit_end(self):
        """Called at end of training"""
        rank_zero_debug("Training complete!")
        
        # Save validation logits for calibration
        if len(self.val_select_logits) > 0:
            import torch
            val_select_logits = torch.cat(self.val_select_logits, dim=0)
            val_select_labels = torch.cat(self.val_select_labels, dim=0)
            torch.save(val_select_logits, "outputs/val_select_logits.pt")
            torch.save(val_select_labels, "outputs/val_select_labels.pt")
            rank_zero_debug("Saved val_select logits for calibration")
        
        if len(self.val_calib_logits) > 0:
            import torch
            val_calib_logits = torch.cat(self.val_calib_logits, dim=0)
            val_calib_labels = torch.cat(self.val_calib_labels, dim=0)
            torch.save(val_calib_logits, "outputs/val_calib_logits.pt")
            torch.save(val_calib_labels, "outputs/val_calib_labels.pt")
            rank_zero_debug("Saved val_calib logits for calibration")
        
        if len(self.val_test_logits) > 0:
            import torch
            val_test_logits = torch.cat(self.val_test_logits, dim=0)
            val_test_labels = torch.cat(self.val_test_labels, dim=0)
            torch.save(val_test_logits, "outputs/val_test_logits.pt")
            torch.save(val_test_labels, "outputs/val_test_labels.pt")
            rank_zero_debug("Saved val_test logits for evaluation")
