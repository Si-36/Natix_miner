# DINOv2 ViT-Base Model Configuration
# Latest 2025-2026 Practices
#
# DINOv2 ViT-B/14:
#   - 86M parameters
#   - 518x518 input
#   - Patch size 14
#   - 768 embedding dim
#
# Performance:
#   - Better accuracy than ViT-S
#   - Slower inference (30-40 FPS on H100)
#   - Higher memory (needs 24GB+ GPU)

# Model architecture
name: dinov2_vitb14
backbone: dinov2_vitb14
pretrained: true
freeze_backbone: false  # Finetune all layers

# Architecture details
architecture:
  patch_size: 14
  embed_dim: 768
  depth: 12
  num_heads: 12
  mlp_ratio: 4.0

# Classifier head
classifier:
  num_classes: 7  # NATIX has 7 classes
  hidden_dim: 1024
  dropout: 0.3
  use_batch_norm: true

# Gate head (for Phase 3)
gate:
  enabled: false  # Only enable in Phase 3
  hidden_dim: 512
  dropout: 0.2
  use_batch_norm: true

# Flash Attention 3 (for H100 GPUs)
flash_attention:
  enabled: true
  version: 3  # Flash Attention 3 (1.5-2Ã— faster on H100)

# Model initialization
init:
  classifier_init: xavier_uniform
  gate_init: xavier_uniform
